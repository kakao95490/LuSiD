{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Downloads :"
      ],
      "metadata": {
        "id": "ozcPgAM1_AkG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8rFpi1f-3Zg",
        "outputId": "8c9c8628-4992-431e-ddc4-06b66fed352e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (0.3.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from kagglehub) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kagglehub) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub) (4.66.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install kagglehub"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import :"
      ],
      "metadata": {
        "id": "Y_kKMa91_DGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "xpgj0BD9-_sU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"rhtsingh/google-universal-image-embeddings-128x128\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXSSNQXD--Qt",
        "outputId": "1b2b510c-7510-476a-ad11-2cac1f59ab20"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/rhtsingh/google-universal-image-embeddings-128x128?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.36G/1.36G [00:21<00:00, 68.5MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/rhtsingh/google-universal-image-embeddings-128x128/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.move(path,\"./\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nGfgQfbv_bAF",
        "outputId": "2d3b767b-8ecb-4d9b-f9f3-9b337b9eb570"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Chemin du dossier d'entrée contenant les images\n",
        "input_dir = \"./1/128x128\"\n",
        "output_dir = \"dataset\"\n",
        "\n",
        "# Proportions pour train, val et test\n",
        "train_ratio = 0.7\n",
        "val_ratio = 0.15\n",
        "test_ratio = 0.15\n",
        "\n",
        "# Vérification que les proportions totalisent 1\n",
        "assert train_ratio + val_ratio + test_ratio == 1, \"Les proportions doivent totaliser 1.\"\n",
        "\n",
        "# Récupérer toutes les images de tous les sous-dossiers\n",
        "images = []\n",
        "for root, _, files in os.walk(input_dir):\n",
        "    for file in files:\n",
        "        if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif', '.tiff')):\n",
        "            images.append(os.path.join(root, file))\n",
        "\n",
        "# Mélanger et diviser les images en train, val et test\n",
        "train_images, temp_images = train_test_split(images, test_size=(1 - train_ratio), random_state=42)\n",
        "val_images, test_images = train_test_split(temp_images, test_size=test_ratio / (test_ratio + val_ratio), random_state=42)\n",
        "\n",
        "# Fonction pour copier les images dans les répertoires de sortie\n",
        "def copy_images(image_list, output_subdir):\n",
        "    output_path = os.path.join(output_dir, output_subdir)\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "    for image_path in image_list:\n",
        "        shutil.copy(image_path, os.path.join(output_path, os.path.basename(image_path)))\n",
        "\n",
        "# Copier les images dans les répertoires train, val et test\n",
        "copy_images(train_images, \"train\")\n",
        "copy_images(val_images, \"val\")\n",
        "copy_images(test_images, \"test\")\n",
        "\n",
        "print(\"Séparation des datasets terminée avec succès !\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KbYCHe3_7dE",
        "outputId": "d2c1a12d-0d5a-4f9c-ea88-ade26898ef09"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Séparation des datasets terminée avec succès !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Nombre d'images dans l'ensemble train : {len(train_images)}\")\n",
        "print(f\"Nombre d'images dans l'ensemble validation : {len(val_images)}\")\n",
        "print(f\"Nombre d'images dans l'ensemble test : {len(test_images)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJhNPePHC-Hc",
        "outputId": "21dad29b-a801-4b34-8f89-f37b61d2dbbd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombre d'images dans l'ensemble train : 92769\n",
            "Nombre d'images dans l'ensemble validation : 19879\n",
            "Nombre d'images dans l'ensemble test : 19880\n"
          ]
        }
      ]
    }
  ]
}